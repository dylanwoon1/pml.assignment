return(prediction)
}
library(kernlab)
set.seed(333)
data(spam)
smallSpam <- spam[sample(dim(spam)[1], size = 10),]
plot(smallSpam$capitalAve, col = spamLabel)
rule1 <- function(x){
prediction <- rep(NA, length(x))
prediction[x > 2.8] <- "spam"
prediction[x <= 2.8] <- "non-spam"
return(prediction)
}
table(rule1(smallSpam$capitalAve), smallSpam$type)
rule2 <- function(x){
prediction <- rep(NA, length(x))
prediction[x > 2.8] <- "spam"
prediction[x <= 2.8] <- "non-spam"
return(prediction)
}
rule1(smallSpam$capitalAve), smallSpam$type
rule2 <- function(x){
prediction <- rep(NA, length(x))
prediction[x > 2.8] <- "spam"
prediction[x <= 2.8] <- "non-spam"
return(prediction)
}
table(rule1(smallSpam$capitalAve), smallSpam$type)
rep(1, 5)
matrix(rep(1, 6), 2, 3)
rule2 <- function(x){
prediction <- rep(NA, length(x))
prediction[x > 2.8] <- "spam"
prediction[x <= 2.8] <- "non-spam"
return(prediction)
}
table(rule2(smallSpam$capitalAve), smallSpam$type)
rule2 <- function(x){
prediction <- rep(NA, length(x))
prediction[x > 2.8] <- "spam"
prediction[x <= 2.8] <- "non-spam"
return(prediction)
}
table(rule2(smallSpam$capitalAve), smallSpam$type)
table(rule)
98901 + 999
98901/99900
99 + 999
900 + 89100
89100/90000
9900 / (9900 + 900)
table(rule2(smallSpam$capitalAve), smallSpam$type)
?table
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
?createDataPartition
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~., data = training, method = "glm")
?train
modelFit <- train(type ~., data = training, method = "glm")
warnings()
args(trainControl)
modelFir
modelFit
library(caret)
data(segmentationData)
View(segmentationData)
dim(segmentationData)
library(caret)
data(segmentationData)
segmentationData$Cell < NULL
View(segmentationData)
library(caret)
data(segmentationData)
segmentationData$Cell < NULL
View(segmentationData)
library(caret)
data(segmentationData)
segmentationData$Cell <- NULL
View(segmentationData)
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationdata, Case == "Test")
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, Case == "Test")
training$Case <- NULL
testing$Case <- NULL
str(training)
View(training)
names(training)
trainX >- training[, names(training) != "Class"]  # remove the "Class" column
segmentationData$Cell <- NULL  # remove cell column
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, Case == "Test")
training$Case <- NULL
testing$Case <- NULL
trainX >- training[, names(training) != "Class"]
trainX >- training[, names(training) != "Class"]
trainX >- training[, names(training) != "Class"]
library(caret)
data(segmentationData)
segmentationData$Cell <- NULL  # remove cell column
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, Case == "Test")
training$Case <- NULL
testing$Case <- NULL
trainX >- training[, names(training) != "Class"]  # remove the "Class" column
library(caret)
data(segmentationData)
segmentationData$Cell <- NULL  # remove cell column
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, Case == "Test")
training$Case <- NULL
testing$Case <- NULL
train2 >- training[, names(training) != "Class"]  # remove the "Class" column
library(caret)
data(segmentationData)
segmentationData$Cell <- NULL  # remove cell column
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, Case == "Test")
training$Case <- NULL
testing$Case <- NULL
trainX <- training[, names(training) != "Class"]  # remove the "Class" column
View(trainx)
View(trainX)
preProcValues <- preProcess(trainX, method = c("center", "scale"))
preProcValues
dim(trainX)
preProcValues <- preProcess(trainX, method = c("center", "ignored", "scale"))
preProcValues <- preProcess(trainX, method = c("center", "scale"))
?predict
scaledTrain <- predict(preProcValues, trainX)
install.packages("twitteR", dependencies = TRUE)
install.packages("RCurl", dependencies = TRUE)
library(RCurl)
library(twitteR)
require(RCurk)
require(RCurl)
require(twitteR)
require(twitteR)
require(RCurl)
consumer_key <- "SSrOaihtrd68HeRtLuxOyYY6K"
consumer_secret <- 	"rR50FxUK70vEyqwQfch3Krb2v1heIWUIPvJxrL9oHOnGpd7NxB"
access_token <- "2309434812-3F09kyfMqKBARK82rRiVVbcfe1HyPzhHGhzy21C"
access_secret <- "xENWDuchv2xcIHzG6lbWthOsb3w3kEvsBwFFhRFksMvjp"
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# search for the first 10 english tweets which contain the word "data"
data_tweets <- searchTwitter("data", n = 10, lang = "en")
data_tweets
install.packages("tm", dependencies = TRUE)
install.packages("wordcloud", dependencies = TRUE)
require(twitteR)
require(RCurl)
require(tm) # text mining
require(wordcloud)
consumer_key <- "SSrOaihtrd68HeRtLuxOyYY6K"
consumer_secret <- 	"rR50FxUK70vEyqwQfch3Krb2v1heIWUIPvJxrL9oHOnGpd7NxB"
access_token <- "2309434812-3F09kyfMqKBARK82rRiVVbcfe1HyPzhHGhzy21C"
access_secret <- "xENWDuchv2xcIHzG6lbWthOsb3w3kEvsBwFFhRFksMvjp"
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# 1 = yes, 2 = no
# search for the first 10 english tweets which contain the word "data"
# result will be in a list
data_tweets <- searchTwitter("data", n = 10, lang = "en")
data_tweets
health_tweets <- searchTwitter("health + male", lang = "en", n = 50, resultType = "recent")
class(health_tweets)
healthmale_text <- sapply(healthmale, function(x) x$getText())
healthmale <- searchTwitter("health + male", lang = "en", n = 50, resultType = "recent")
class(healthmale)
# convert list to character
healthmale_text <- sapply(healthmale, function(x) x$getText())
class(healthmale)
class(healthmale_text)
healthmale_corpus <- Corpus(VectorSource(healthmale_text))
healthmale_corpus
inspect(healthmale_corpus[1])
healthmale_clean <- tm_map(healthmale_corpus, removePunctuation)
?removeWords
?stopwords
healthmale_clean <- tm_map(healthmale_clean, stripWhitespace)
healthmale_clean <- tm_map(healthmale_corpus, removePunctuation)
healthmale_clean <- tm_map(healthmale_clean, content_transformer(tolower))
healthmale_clean <- tm_map(healthmale_clean, removeWords, stopwords("en"))
healthmale_clean <- tm_map(healthmale_clean, removeNumbers)
healthmale_clean <- tm_map(healthmale_clean, stripWhitespace)
healthmale_clean <- tm_map(healthmale_clean, removeWords, c("health", "male"))
?stripWhitespace
healthmale_clean <- tm_map(healthmale_corpus, removePunctuation)
healthmale_clean <- tm_map(healthmale_clean, content_transformer(tolower))
healthmale_clean <- tm_map(healthmale_clean, removeWords, stopwords("en"))
healthmale_clean <- tm_map(healthmale_clean, removeNumbers)
healthmale_clean <- tm_map(healthmale_clean, stripWhitespace)
healthmale_clean <- tm_map(healthmale_clean, removeWords, c("health", "male"))
worldcloud(healthmale_clean)
wordcloud(healthmale_clean)
wordcloud(healthmale_clean, random.order = T, scale = c(3, 0.5))
wordcloud(healthmale_clean, random.order = T, scale = c(5, 0.5))
wordcloud(healthmale_clean, random.order = T, scale = c(3, 0.5))
wordcloud(healthmale_clean, random.order = T, scale = c(3, 0.5), col = rainbow(50))
wordcloud(healthmale_clean, random.order = T, scale = c(3, 0.5), col = rainbow(30))
wordcloud(healthmale_clean, random.order = T, scale = c(3, 0.5), col = rainbow(30), max.words = 50)
download.packages("class", dependencies = TRUE)
download.packages("class", dependencies = TRUE)
1 + 1
download.packages("class", dependencies = TRUE)
download.packages("tm", dependencies = TRUE)
download.packages("tm", dependencies = TRUE)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("AppliedPredictiveModeling", "pgmm", "rpart", "gbm", "lubridate", "forecast", "e1071")
ipak(packages)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.train)
View(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rf.fit <- train(y ~ . , data = vowel.train, method = "rf")
library(caret)
rf.fit <- train(y ~ . , data = vowel.train, method = "rf")
rf.fit <- train(y ~ . , data = vowel.train, method = "rf")
rf.predict <- predict(rf.fit, vowel.test)
onfusionMatrix(RFpred,vowel.test$y)
confusionMatrix(RFpred,vowel.test$y)
confusionMatrix(rf.predict,vowel.test$y)
confusionMatrix(rf.predict,vowel.test$y)$overall["Accuracy"]
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
rf.fit <- train(y ~ . , data = vowel.train, method = "rf")
?train
?predict
gbm.fit <- train(y ~ . , data = vowel.train, method = "gbm", verbose = FALSE)
gbm.predict <- predict(gbm.fit, vowel.test)
confusionMatrix(rf.predict, vowel.test$y)$overall["accuracy"]
confusionMatrix(rf.predict, vowel.test$y)$overall["Accuracy"]
confusionMatrix(gbm.predict, vowel.test$y)$overall["Accuracy"]
aa <- rf.predict == gbm.predict
bb <- vowel.test$y == rf.predict
sum(aa*bb)/sum(aa)
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
View(AlzheimerDisease)
View(AlzheimerDisease)
data(AlzheimerDisease)
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
head(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
adData
View(adData)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
?createDataPartition
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
set.seed(62433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf.fit <- train(diagnosis ~ ., data = training, method = "rf")
confusionMatrix(rf.predict, testing$diagnosis)$overall["Accuracy"]
rf.predict <- predict(rf.fit, testing)
confusionMatrix(rf.predict, testing$diagnosis)$overall["Accuracy"]
gbm.fit <- train(diagnosis ~ ., data = training, method = "gbm")
gbm.fit <- train(diagnosis ~ ., data = training, method = "gbm", verbose = F)
gbm.predict <- predict(gbm.fit, testing)
confusionMatrix(gbm.predict, testing$diagnosis)$overall["Accuracy"]
lda.fit <- train(diagnosis ~ ., data = training, method = "lda")
lda.predict <- predict(lda.fit, testing)
confusionMatrix(lda.predict, testing$diagnosis)$overall["Accuracy"]
gam.fit <- train(diagnosis ~ ., data = training, method = "gam")
gam.predict <- predict(gam.fit, testing)
confusionMatrix(gam.predict, testing$diagnosis)$overall["Accuracy"]
gam.fit <- train(diagnosis ~ ., data = training, method = "gam")
gam.predict <- predict(gam.fit, testing)
confusionMatrix(gam.predict, testing$diagnosis)$overall["Accuracy"]
confusionMatrix(rf.predict, testing$diagnosis)$overall["Accuracy"]
confusionMatrix(gbm.predict, testing$diagnosis)$overall["Accuracy"]
confusionMatrix(lda.predict, testing$diagnosis)$overall["Accuracy"]
confusionMatrix(gam.predict, testing$diagnosis)$overall["Accuracy"]
gam.predict <- predict(gam.fit, testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?plot.enet
install.packages("elasticnet", dependencies = TRUE)
?enet
library(elasticnet)
?enet
set.seed(233)
LASSOfit <-  enet(x=data.matrix(LASSOtraining[1:8]),y=LASSOtraining$CompressiveStrength,lambda=1)
plot(LASSOfit, use.color=TRUE)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
LASSOtraining = concrete[ inTrain,]
LASSOtesting = concrete[-inTrain,]
set.seed(233)
LASSOfit <-  enet(x=data.matrix(LASSOtraining[1:8]),y=LASSOtraining$CompressiveStrength,lambda=1)
plot(LASSOfit, use.color=TRUE)
View(concrete)
# https://rstudio-pubs-static.s3.amazonaws.com/28753_c3f068c4cced42ae8697070e34bbef12.html
setwd("~/R directory/Coursera Assignment/[Coursera] Module 8 Week 4")
train <- read.csv("train.csv", na.strings = c("#DIV/0!"), row.names = 1)
test <- read.csv("test.csv", na.strings = c("#DIV/0!"), row.names = 1)
str(train) # 19622 obs of 160 variables
str(test) # 20 obs of 160 variables
length(unique(train$user_name)) # 6 unique users
length(unique(test$user_name)) # 6 unique users
train <- train[ , 6 : dim(train)[2]]
test <- test[ , 6 : dim(test)[2]]
# some columns have a majority of NAs. Remove columns with >= 80% NAs
na.threshold <- dim(train)[1] * 0.8
na.smallerthanthreshold <- !apply(train, 2, function(x) sum(is.na(x)) > na.threshold || sum(x == "") > na.threshold)
train <- train[, na.smallerthanthreshold]
# remove predictors with near zero variance
nzv.table <- nearZeroVar(train, saveMetrics = T) # return data frame with predictor information
train <- train[, nzv.table$nzv == F]
# objective
# predict how well the 6 users conduct their activities
# This is quanlitatively recorded the "classe" variable in the training set.
table(train$classe)
# use cross validation to estimate the predicted error
# separate training data into training set and validation set to validate our model
# cross validation setup
# train.csv
inTrain <- createDataPartition(train$classe, p = 0.75)[[1]]
train <- train[inTrain, ]
crossvad <- train[-inTrain, ]
inTrain <- createDataPartition(cross.vad$classe, p = 0.75)[[1]]
crossvad.train <- crossvad[inTrain, ]
crossvad.test <- crossvad[-inTrain, ]
# test.csv
test <- test[, na.smallerthanthreshold]
test$classe <- NA
nzv.table <- nearZeroVar(test, saveMetrics = T) # return data frame with predictor information
test <- test[, nzv.table$nzv == F]
# train, predict, confusion matrix
rf.fit <- train(classe ~ ., data = train, method = "rf")
gbm.fit <- train(classe ~ ., data = train, method = "gbm")
lda.fit <- train(classe ~ ., data = train, method = "lda")
rf.predict <- predict(rf.fit, crossvad)
gbm.predict <- predict(gbm.fit, crossvad)
lda.predict <- predict(lda.fit, crossvad)
rf.cm <- confusionMatrix(rf.predict, crossvad$classe)
gbm.cm <- confusionMatrix(gbm.predict, crossvad$classe)
lda.cm <- confusionMatrix(lda.predict, crossvad$classe)
# combination model
DF.predict <- data.frame(rf.predict, bgm.predict , classe = crossv$classe)
combinedModel.fit <- train(classe ~ ., method = "rf", data = DF.predict)
#in-sample error
insampleError <- predict(combinedModel.fit, predict.DF)
confusionMatrix(insampleError, DF.predict$classe)
#out-of-sample error
rf.predictcrossv <- predict(rf.fit, crossv_test) # why is bgm left out?
lda.predictcrossv <- predict(lda.fit, crossv_test)
accuracy <- sum(rf.predictcrossv == crossv_test$classe) / length(rf.predictcrossv)
# https://rstudio-pubs-static.s3.amazonaws.com/28753_c3f068c4cced42ae8697070e34bbef12.html
setwd("~/R directory/Coursera Assignment/[Coursera] Module 8 Week 4")
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(gbm)
library(doParallel)
library(survival)
library(splines)
library(plyr)
train <- read.csv("train.csv", na.strings = c("#DIV/0!"), row.names = 1)
test <- read.csv("test.csv", na.strings = c("#DIV/0!"), row.names = 1)
str(train) # 19622 obs of 160 variables
str(test) # 20 obs of 160 variables
length(unique(train$user_name)) # 6 unique users
length(unique(test$user_name)) # 6 unique users
train <- train[ , 6 : dim(train)[2]]
test <- test[ , 6 : dim(test)[2]]
# some columns have a majority of NAs. Remove columns with >= 80% NAs
na.threshold <- dim(train)[1] * 0.8
na.smallerthanthreshold <- !apply(train, 2, function(x) sum(is.na(x)) > na.threshold || sum(x == "") > na.threshold)
train <- train[, na.smallerthanthreshold]
# remove predictors with near zero variance
nzv.table <- nearZeroVar(train, saveMetrics = T) # return data frame with predictor information
train <- train[, nzv.table$nzv == F]
# objective
# predict how well the 6 users conduct their activities
# This is quanlitatively recorded the "classe" variable in the training set.
table(train$classe)
# use cross validation to estimate the predicted error
# separate training data into training set and validation set to validate our model
# cross validation setup
# train.csv
inTrain <- createDataPartition(train$classe, p = 0.75)[[1]]
train <- train[inTrain, ]
crossvad <- train[-inTrain, ]
inTrain <- createDataPartition(cross.vad$classe, p = 0.75)[[1]]
crossvad.train <- crossvad[inTrain, ]
crossvad.test <- crossvad[-inTrain, ]
# test.csv
test <- test[, na.smallerthanthreshold]
test$classe <- NA
nzv.table <- nearZeroVar(test, saveMetrics = T) # return data frame with predictor information
test <- test[, nzv.table$nzv == F]
# train, predict, confusion matrix
rf.fit <- train(classe ~ ., data = train, method = "rf")
# https://rstudio-pubs-static.s3.amazonaws.com/28753_c3f068c4cced42ae8697070e34bbef12.html
setwd("~/R directory/Coursera Assignment/[Coursera] Module 8 Week 4")
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(gbm)
library(doParallel)
library(survival)
library(splines)
library(plyr)
train <- read.csv("train.csv", na.strings = c("#DIV/0!"), row.names = 1)
test <- read.csv("test.csv", na.strings = c("#DIV/0!"), row.names = 1)
str(train) # 19622 obs of 160 variables
str(test) # 20 obs of 160 variables
length(unique(train$user_name)) # 6 unique users
length(unique(test$user_name)) # 6 unique users
train <- train[ , 6 : dim(train)[2]]
test <- test[ , 6 : dim(test)[2]]
# some columns have a majority of NAs. Remove columns with >= 80% NAs
na.threshold <- dim(train)[1] * 0.8
na.smallerthanthreshold <- !apply(train, 2, function(x) sum(is.na(x)) > na.threshold || sum(x == "") > na.threshold)
train <- train[, na.smallerthanthreshold]
# remove predictors with near zero variance
nzv.table <- nearZeroVar(train, saveMetrics = T) # return data frame with predictor information
train <- train[, nzv.table$nzv == F]
# objective
# predict how well the 6 users conduct their activities
# This is quanlitatively recorded the "classe" variable in the training set.
table(train$classe)
# use cross validation to estimate the predicted error
# separate training data into training set and validation set to validate our model
# cross validation setup
# train.csv
inTrain <- createDataPartition(train$classe, p = 0.75)[[1]]
train <- train[inTrain, ]
crossvad <- train[-inTrain, ]
inTrain <- createDataPartition(crossvad$classe, p = 0.75)[[1]]
crossvad.train <- crossvad[inTrain, ]
crossvad.test <- crossvad[-inTrain, ]
# test.csv
test <- test[, na.smallerthanthreshold]
test$classe <- NA
nzv.table <- nearZeroVar(test, saveMetrics = T) # return data frame with predictor information
test <- test[, nzv.table$nzv == F]
# train, predict, confusion matrix
rf.fit <- train(classe ~ ., data = train, method = "rf")
gbm.fit <- train(classe ~ ., data = train, method = "gbm")
lda.fit <- train(classe ~ ., data = train, method = "lda")
rf.predict <- predict(rf.fit, crossvad)
gbm.predict <- predict(gbm.fit, crossvad)
lda.predict <- predict(lda.fit, crossvad)
rf.cm <- confusionMatrix(rf.predict, crossvad$classe)
gbm.cm <- confusionMatrix(gbm.predict, crossvad$classe)
lda.cm <- confusionMatrix(lda.predict, crossvad$classe)
# combination model
DF.predict <- data.frame(rf.predict, bgm.predict , classe = crossv$classe)
combinedModel.fit <- train(classe ~ ., method = "rf", data = DF.predict)
#in-sample error
insampleError <- predict(combinedModel.fit, predict.DF)
confusionMatrix(insampleError, DF.predict$classe)
#out-of-sample error
rf.predictcrossv <- predict(rf.fit, crossv_test) # why is bgm left out?
lda.predictcrossv <- predict(lda.fit, crossv_test)
accuracy <- sum(rf.predictcrossv == crossv_test$classe) / length(rf.predictcrossv)
